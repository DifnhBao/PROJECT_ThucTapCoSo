import os
import random
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn th∆∞ m·ª•c LEARN
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# K·∫øt n·ªëi ch√≠nh x√°c ƒë·∫øn file csv
DATA_PATH = os.path.join(BASE_DIR, 'data', 'Trainning', 'final_training_data_v2.csv')

# 1. ƒê·ªçc d·ªØ li·ªáu
train_data = pd.read_csv(DATA_PATH)

# --- X·ª≠ l√Ω Mean-Centering ---
# T√≠nh ƒëi·ªÉm trung b√¨nh c·ªßa m·ªói User (ch·ªâ t√≠nh tr√™n nh·ªØng b√†i h·ªç ƒë√£ rating)
# Tr·∫£ l·ªùi cho c√¢u h·ªèi: "Trung b√¨nh th√¨ ng∆∞·ªùi n√†y th∆∞·ªùng ch·∫•m bao nhi√™u ƒëi·ªÉm?""
user_means = train_data.groupby('user_id')['rating'].mean()

# T·∫°o ma tr·∫≠n g·ªëc (kh√¥ng fillna ngay ƒë·ªÉ tr·ª´ trung b√¨nh ch√≠nh x√°c)
# Tr·∫£ l·ªùi cho c√¢u h·ªèi: "Ng∆∞·ªùi n√†o ch·∫•m b√†i h√°t n√†o bao nhi√™u ƒëi·ªÉm?"
user_item_matrix = train_data.pivot_table(index='user_id', columns='song_id', values='rating')

# Tr·ª´ ƒëi ƒëi·ªÉm trung b√¨nh c·ªßa m·ªói User (Mean-Centering)
# Nh·ªØng b√†i ch∆∞a nghe s·∫Ω mang gi√° tr·ªã NaN, nh·ªØng b√†i ƒë√£ nghe s·∫Ω c√≥ ƒëi·ªÉm quanh m·ªëc 0
user_item_matrix_centered = user_item_matrix.sub(user_means, axis=0).fillna(0)

# 2. T·∫°o Pivot Table (Ma tr·∫≠n User-Item)
user_item_matrix = user_item_matrix.fillna(0)

# 3. Chuy·ªÉn sang Sparse Matrix ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng
sparse_matrix_centered = csr_matrix(user_item_matrix_centered.values)

# 4. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c User
user_similarity = cosine_similarity(sparse_matrix_centered)
user_sim_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)

def get_recommendations(target_user_id, num_to_show=10, candidate_pool=50):
    if target_user_id not in user_sim_df.index:
        return [] # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ng∆∞·ªùi d√πng m·ªõi (Cold Start)

    # T√¨m 5 ng∆∞·ªùi d√πng gi·ªëng nh·∫•t
    similar_users = user_sim_df[target_user_id].sort_values(ascending=False).iloc[1:6].index

    # L·∫•y c√°c b√†i h√°t h·ªç th√≠ch
    similar_user_songs = user_item_matrix.loc[similar_users].mean(axis=0).sort_values(ascending=False)
    
    # L·ªçc b√†i h√°t user m·ª•c ti√™u ƒë√£ nghe r·ªìi
    user_heard = user_item_matrix.loc[target_user_id]
    already_heard = user_heard[user_heard > 0].index

    # L·∫•y danh s√°ch c√°c ·ª©ng vi√™n t·ªët nh·∫•t (Candidate Pool)
    potential_recommendations = similar_user_songs.drop(already_heard).head(candidate_pool)

    # Chuy·ªÉn index sang list b√†i h√°t
    recommendation_list = potential_recommendations.index.tolist()
    
    # N·∫øu s·ªë l∆∞·ª£ng ·ª©ng vi√™n t√¨m ƒë∆∞·ª£c √≠t h∆°n ho·∫∑c b·∫±ng s·ªë l∆∞·ª£ng c·∫ßn hi·ªÉn th·ªã, tr·∫£ v·ªÅ to√†n b·ªô
    if len(recommendation_list) <= num_to_show:
        return recommendation_list
    
    # Ch·ªçn ng·∫´u nhi√™n num_to_show b√†i h√°t t·ª´ danh s√°ch ·ª©ng vi√™n
    return random.sample(recommendation_list, num_to_show)


# ==========TEST===========

# --- H√†m h·ªó tr·ª£ l·∫•y t√™n b√†i h√°t t·ª´ ID ---
def get_song_titles(song_ids):
    # L·∫•y c√°c h√†ng c√≥ song_id n·∫±m trong danh s√°ch, sau ƒë√≥ lo·∫°i b·ªè tr√πng l·∫∑p v√† t·∫°o t·ª´ ƒëi·ªÉn tra c·ª©u
    titles_map = train_data[train_data['song_id'].isin(song_ids)][['song_id', 'title']].drop_duplicates()
    titles_dict = dict(zip(titles_map['song_id'], titles_map['title']))
    
    # Tr·∫£ v·ªÅ danh s√°ch t√™n theo ƒë√∫ng th·ª© t·ª± c·ªßa song_ids truy·ªÅn v√†o
    return [titles_dict.get(sid, "Unknown Song") for sid in song_ids]

# Test th·ª≠ cho m·ªôt User b·∫•t k·ª≥ trong d·ªØ li·ªáu
sample_user = train_data['user_id'].iloc[0]

# print(f"L·∫ßn 1 - G·ª£i √Ω cho User {sample_user}: {get_recommendations(sample_user)}")
# print(f"L·∫ßn 2 - G·ª£i √Ω cho User {sample_user}: {get_recommendations(sample_user)}")

# L·∫•y danh s√°ch ID g·ª£i √Ω
rec_ids_1 = get_recommendations(sample_user)
rec_ids_2 = get_recommendations(sample_user)

# Chuy·ªÉn ƒë·ªïi sang t√™n b√†i h√°t
rec_titles_1 = get_song_titles(rec_ids_1)
rec_titles_2 = get_song_titles(rec_ids_2)

print(f"\nüéØ G·ª£i √Ω cho User: {sample_user}")
print(f"--------------------------------------------------")
print(f"L·∫ßn 1 (Ng·∫´u nhi√™n t·ª´ Top 50):")
for i, title in enumerate(rec_titles_1, 1):
    print(f"{i}. {title}")

print(f"\nL·∫ßn 2 (ƒê·ªÉ ki·ªÉm tra t√≠nh ƒëa d·∫°ng):")
for i, title in enumerate(rec_titles_2, 1):
    print(f"{i}. {title}")

def verify_neighbors(target_user_id):
    # T√¨m 5 ng∆∞·ªùi gi·ªëng nh·∫•t
    sim_users = user_sim_df[target_user_id].sort_values(ascending=False).iloc[1:6]
    print(f"--- Ki·ªÉm tra h√†ng x√≥m c·ªßa {target_user_id} ---")
    for user, score in sim_users.items():
        # L·∫•y top 3 b√†i h√°t m√† 'h√†ng x√≥m' n√†y ƒë√°nh gi√° cao nh·∫•t
        top_songs = train_data[train_data['user_id'] == user].sort_values(by='rating', ascending=False).head(3)['title'].tolist()
        print(f"H√†ng x√≥m: {user} (ƒê·ªô gi·ªëng: {score:.2f}) - Th√≠ch: {top_songs}")

verify_neighbors(sample_user)